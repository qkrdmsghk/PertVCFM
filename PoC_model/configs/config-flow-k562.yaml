wandb:
  project: TxPertzz
  name: None # seed_2-$(date +%Y-%m-%d-%H-%M) 
  save_dir: "wandb_logs"

debug: false

model:
  model_type: txpertflow
  no_basal_model: false
  no_pert_model: false
  bce_loss: false
  hidden_dim: 512 # control_mean needs 2048
  latent_dim: 512 # for pert output dim
  dropout: 0.2
  lr: 1e-3
  use_batch_norm: true
  use_layer_norm: false
  omit_cntr: false
  mse_weight: 1
  slow_benchmark: false 
  
  cntr_model:
    model_type: mlp
    rank: 16
    decode_latent: false
    use_batch_norm: true
    use_layer_norm: false

  pert_model:
    model_type: gnn # None
    layer_type: gat_v2
    num_layers: 4
    hidden_dim: 128 # for pert hidden dim
    skip: skip_cat
    dropout: 0.2
    num_heads: 2
    concat: true
    add_self_loops: true
    use_edge_weight: false
    use_struc_feat: false
    use_graph: true # use prior knowledge graph or not 11/12/2025
  
  flow_model:
    model_type: random_noise # random_noise, control_mean, noised_control_mean
    noise_scale: 0.05
    cond: control_mean # no_control, control_mean, random_control, ot_control
    network_type: v4 # v1, v2, v3, v4, v5
    num_flow_steps: 50
    latent_flow: false
    ae_checkpoint: null


datamodule:
  mode: ${mode}
  task_type: K562_single_cell_line
  match_cntr: true
  avg_cntr: true
  batch_size: 64 # control_mean needs 2048
  embed_cntr: true
  obsm_key: raw
  p_emb_key: nonono # scGenePT or GenePert or GenePertESM 11/02/2025
  mask_degs: None

graph:
  graph_cfg:
    graph1:
      graph_type: string
      reduce2perts: true
      norm_weights: false
      mode: top_20
      p_downsample: 1.0
      p_rewire_src: 0.0
      p_rewire_tgt: 0.0

seed: 1
match_cntr_for_eval: true
max_epochs: 200
# mode: baseline
# checkpoint_name: null

mode: baseline
checkpoint_name: perturbqa_K562_unseen_pert_llm.ckpt